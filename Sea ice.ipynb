{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Dacon_V4",
      "provenance": [],
      "collapsed_sections": [
        "BcjBoC7VXXTD"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Doongwoooo/Dacon/blob/master/Sea%20ice.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nG0WKWwTfeE1"
      },
      "source": [
        "import os, glob\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import datasets, layers, models, Input\n",
        "from keras.models import Sequential\n",
        "import numpy as np\n",
        "import pylab as plt\n",
        "\n",
        "import re\n",
        "patten_date = re.compile('\\d{6}')\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model, Model\n",
        "from tensorflow.keras.layers import Conv3D, ConvLSTM2D, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EV7tdB6ApYB-",
        "outputId": "1685dcbc-7ff4-41d6-ac47-cbacc11ff20b"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tE8nnUSgdNwV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf16c28-e7e3-4068-96c5-95e932aaec4f"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow version 2.4.1\n",
            "Running on TPU  ['10.110.162.82:8470']\n",
            "INFO:tensorflow:Initializing the TPU system: grpc://10.110.162.82:8470\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Initializing the TPU system: grpc://10.110.162.82:8470\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Clearing out eager caches\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished initializing TPU system.\n",
            "WARNING:absl:`tf.distribute.experimental.TPUStrategy` is deprecated, please use  the non experimental symbol `tf.distribute.TPUStrategy` instead.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Found TPU system:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Workers: 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zrdzvg42pKYa"
      },
      "source": [
        "def load_npy(path):\n",
        "    npy = np.load(path)\n",
        "    return npy\n",
        "\n",
        "def show_data(npy):\n",
        "    num_channel = npy.shape[-1]\n",
        "    plt.figure(figsize=(3*num_channel, 5))\n",
        "    for channel in range(num_channel):\n",
        "        tmpimg = npy[:, :, channel]\n",
        "        plt.subplot(1, num_channel, channel+1)\n",
        "        plt.imshow(tmpimg)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()\n",
        "\n",
        "def show_one_data(npy):\n",
        "    num_channel = npy.shape[-1]\n",
        "    plt.figure(figsize=(3, 5))\n",
        "    tmpimg = npy[:, :]\n",
        "    plt.imshow(tmpimg)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    plt.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFEhOmxLerld"
      },
      "source": [
        "path = '/content/drive/MyDrive/Dacon/train/'\n",
        "folder = list(os.listdir(path))\n",
        "train_path = sorted(glob.glob(path+'train/*.npy'))\n",
        "train_path = train_path[-30*12:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uP6v0j1eoNAG"
      },
      "source": [
        "X_map = []\n",
        "X_mon = []\n",
        "for file in folder:\n",
        "    npy = (load_npy(path + file)[:, :, 0] + load_npy(path + file)[:, :, 1])/250\n",
        "    X_map.append(np.array(npy))\n",
        "    date = str(patten_date.match(file))\n",
        "    X_mon.append(date[-2:])\n",
        "X_map = np.array(X_map)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeDg9J9LrdnM",
        "outputId": "b4178841-9521-4b50-e3c2-610832758def"
      },
      "source": [
        "X_map.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(494, 448, 304)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jgb6TyAsgtVH"
      },
      "source": [
        "window_size = 12 * 2 # 몇년?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PWRwFcEggvf9"
      },
      "source": [
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "for i in range(X_map.shape[0]-window_size):\n",
        "    x_train.append(X_map[i:i+window_size, :, :])\n",
        "    y_train.append(X_map[i+window_size:i+window_size+1, :, :])\n",
        "    \n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwo2h6ZigxdP"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pSNaQb0g12g"
      },
      "source": [
        "stride = 64\n",
        "feature_size = 128\n",
        "x_train_ = []\n",
        "y_train_ = []\n",
        "for y in range(x_train.shape[0]):\n",
        "    for i in range((x_train.shape[2]-feature_size)//stride+1):\n",
        "        for j in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "            x_ = x_train[y, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size]\n",
        "            y_ = y_train[y, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size]\n",
        "            x_train_.append(x_)\n",
        "            y_train_.append(y_)\n",
        "\n",
        "x_train_ = np.array(x_train_)\n",
        "y_train_ = np.array(y_train_)\n",
        "\n",
        "x_val_ = []\n",
        "y_val_ = []\n",
        "\n",
        "for i in range((x_train.shape[2]-feature_size)//stride+1):\n",
        "    for j in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "        x_ = x_train[-1, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size]\n",
        "        y_ = y_train[-1, :, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size]\n",
        "        x_val_.append(x_)\n",
        "        y_val_.append(y_)\n",
        "            \n",
        "x_val_ = np.array(x_val_)\n",
        "y_val_ = np.array(y_val_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6vA-Ja3RhAgk"
      },
      "source": [
        "x_train_.shape, y_train_.shape, x_val_.shape, y_val_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-SeoV1cchW6m"
      },
      "source": [
        "with strategy.scope():\n",
        "    ice_input = Input((None, x_train_.shape[2], x_train_.shape[3]))\n",
        "\n",
        "    convLSTM = ConvLSTM2D(filters=64, kernel_size=3, padding='same', return_sequences=True)(ice_input)\n",
        "    convLSTM = BatchNormalization()(convLSTM)\n",
        "\n",
        "    convLSTM = ConvLSTM2D(filters=64, kernel_size=3, padding='same', return_sequences=True)(convLSTM)\n",
        "    convLSTM = BatchNormalization()(convLSTM)\n",
        "\n",
        "    convLSTM = ConvLSTM2D(filters=64, kernel_size=3, padding='same', return_sequences=True)(convLSTM)\n",
        "    convLSTM = BatchNormalization()(convLSTM)\n",
        "\n",
        "    month_input = Input((None))\n",
        "    month_layer = layers.Dense(1)\n",
        "\n",
        "    concat = layers.concatenate([convLSTM, month_layer], axis = -1)\n",
        "    conca_layer = layers.dense((samples.shape[-1]), activation = 'relu')(concat)\n",
        "\n",
        "    outputs = Conv3D(filters=1, kernel_size=3, activation='relu', padding='same', data_format='channels_last')(conca_layer)\n",
        "\n",
        "    model = Model(inputs, outputs)\n",
        "    model.compile(loss='mae', optimizer=Adam())\n",
        "    \n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0bDgXtughx6y"
      },
      "source": [
        "if not (os.path.isdir('models')):\n",
        "    os.makedirs('models')\n",
        "\n",
        "callbacks_list = [\n",
        "    tf.keras.callbacks.ModelCheckpoint(\n",
        "        filepath = './models/convlstm_model.h5',\n",
        "        monitor='val_loss',\n",
        "        save_best_only=True\n",
        "    )\n",
        "]\n",
        "\n",
        "hist = model.fit(train_dataset, epochs=20, validation_data=val_dataset, callbacks=callbacks_list) #두 시간 가량 소요"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HevR-lcth1kn"
      },
      "source": [
        "plt.plot(hist.history['loss'][1:])\n",
        "plt.plot(hist.history['val_loss'][1:])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUWLYHMdiiAZ"
      },
      "source": [
        "model = load_model('./models/convlstm_model.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdHnjK85ilCw"
      },
      "source": [
        "pred = model.predict(next(iter(val_dataset))[0])\n",
        "pred = np.where(pred>250, 250, pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OHAoYxy9inQ3"
      },
      "source": [
        "for i in range(BATCH_SIZE):\n",
        "    plt.subplot(141)\n",
        "    plt.imshow(next(iter(val_dataset))[1][i,0,:,:,0])\n",
        "    plt.subplot(142)\n",
        "    plt.imshow(pred[i,0,:,:,0])\n",
        "    plt.show()\n",
        "    print(np.mean(np.abs(next(iter(val_dataset))[1][i,0,:,:,0] - pred[i,0,:,:,0])))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UOElffsZiqU2"
      },
      "source": [
        "x_test = train_month[:,-1*window_size:,:,:,:1]\n",
        "x_test = np.swapaxes(x_test , 0, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zFtP2WX5j7Z"
      },
      "source": [
        "x_test_ = []\n",
        "for m in range(12):\n",
        "    feature = []\n",
        "    for i in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "        for j in range((x_train.shape[4]-feature_size)//stride+1):\n",
        "            x_ = x_test[:, m, stride*i:stride*i+feature_size, stride*j:stride*j+feature_size, :1]/250\n",
        "            feature.append(x_)\n",
        "    feature = np.array(feature)\n",
        "    x_test_.append(feature)\n",
        "x_test_ = np.array(x_test_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-VraQ4ND5mTi"
      },
      "source": [
        "x_test_.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-PC8OZUX5oO1"
      },
      "source": [
        "preds = []\n",
        "for m in tqdm(range(12)):\n",
        "    pred = model.predict(x_test_[m])\n",
        "    pred = np.where(pred>250, 250, pred)\n",
        "    preds.append(pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xXYgIv5m5rM2"
      },
      "source": [
        "voting_mask = np.zeros((x_train.shape[-3], x_train.shape[-2]))\n",
        "ones = np.ones((feature_size, feature_size))\n",
        "\n",
        "for i in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "    for j in range((x_train.shape[4]-feature_size)//stride+1):\n",
        "        voting_mask[stride*i:stride*i+feature_size, stride*j:stride*j+feature_size] += ones"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xCoBawDD5uA5"
      },
      "source": [
        "plt.imshow(voting_mask)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BbxICoVm5vvq"
      },
      "source": [
        "results = []\n",
        "for m in range(12):\n",
        "    pred = np.zeros((x_train.shape[-3], x_train.shape[-2]))\n",
        "    k = 0\n",
        "    for i in range((x_train.shape[3]-feature_size)//stride+1):\n",
        "        for j in range((x_train.shape[4]-feature_size)//stride+1):\n",
        "            pred[stride*i:stride*i+feature_size, stride*j:stride*j+feature_size] += preds[m][k,-1,:,:,0]\n",
        "            k+=1\n",
        "    pred /= voting_mask\n",
        "    results.append(pred[:448, :304])\n",
        "results = np.array(results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahOhCovw5yGr"
      },
      "source": [
        "for m in range(12):\n",
        "    plt.imshow(results[m])\n",
        "    plt.show()\n",
        "    print(m+1, '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAJ4waJh51HB"
      },
      "source": [
        "submission = pd.read_csv(path+'sample_submission.csv')\n",
        "submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyIn7Y5_56Sp"
      },
      "source": [
        "sub_2019 = submission.loc[:11, ['month']].copy()\n",
        "sub_2020 = submission.loc[12:].copy()\n",
        "\n",
        "sub_2019 = pd.concat([sub_2019, (pd.DataFrame(results.reshape([12,-1])))], axis=1)\n",
        "sub_2019.columns = submission.columns\n",
        "submission = pd.concat([sub_2019, sub_2020])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qsxmi11l58xW"
      },
      "source": [
        "submission"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kRHl030l59Qk"
      },
      "source": [
        "submission.to_csv(path+'submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}